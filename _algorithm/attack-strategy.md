---
layout: default
title: Problem Solving Strategies
---

{% include katex.html %}

# Ad-hoc

* 从input开始考虑（遍历每一个input），前进一步步到达output；或者从output开始考虑（遍历每一个output），后退一步步到达input。
   * 根据input，output的形式，选择合适方法。
      * UVa 10205。直接从output反推回去，直接得到答案，实现上更高效。
      * UVa 10189。从input开始，更新output。因为只有input有值得时候才需要处理，所以更高效。
      * UVa 10360。输入数据量是20K，每个数据影响到50 * 50个cell；整个网格是1025 * 1025个cell。
         * 遍历每一个cell，查看被哪些输入影响到: 1025 * 1025 * 50 * 50 ~ 2500M.
         * 遍历每一个input，更新影响到的cell: 20K * 50 * 50 ~ 50M.

   * 从整体上可以看作：
      * $M*input=output$
      * 算法1，$\begin{pmatrix} m1 \\ m2 \\ \dots \end{pmatrix} * In = \begin{pmatrix} out1 \\ out2 \\ \dots \end{pmatrix}$, m1是行向量，In是列向量，**out1是标量**。
      * 算法2，$\begin{pmatrix} m1 \ m2 \ \dots \end{pmatrix} * \begin{pmatrix} in1 \\ in2 \\ \dots \end{pmatrix} = Out$, m1是列向量，**in1是标量**，Out是列向量。
      * 标量是展开遍历的量。当其有效值很少时（比如0占绝大多数），意味着展开它计算 ，计算量小。

   * 不只是局限于input,output；处理关系的时候都可以从两个方向考虑。
      * uva 11902。可以先固定一个点，考虑它能够dominate哪些其它点；也可以固定一个点，考虑哪些点能够dominate它。前一个方式通过DFS处理起来非常直观。

* 从上一步得到当前步的时候，（或反向，或从当前步到下一步）
   * 分析当前状态；
   * 分析上一步的状态；
   * 从上一步到当前步有哪些变化；上一步的信息/结果是不是有助于当前步的分析/计算。

* 从问题的反面/补集思考。
   * UVA 295. 什么情况下能通过? -> 什么情况下不能通过？-> 任何地方从上到下能连成一堵墙就无法通过。

* Binary-Search。
   * 只要符合单调特性，就能考虑使用。
   * 符合条件的最小/最大值，可能就是一种单调（0变到1）。
   * 猜想一个值，把值代进去，能够快速算出结果，才值得使用。
   * E.g. UVA 1079.

* DP.
   * 可以先考虑complete search。和一般的complete search不同，状态转换是要考虑所有边，而不是随便一条边就行。然后提取出overlapping sub-structures。
      - 如果只考虑第一步的话，可能会忽略一些重要参数。需要多考虑几步；或者进一步从一个中间状态开始分析。
   * 在Bottom-Up模式中，可以双向考虑：遍历input，更新output；遍历output，根据依赖的input计算值。（参见input-output的方向问题）
      * 两个方向虽然本质是一样的，但某个方向更有助于理清楚逻辑。
      * 但是向前向后两个方向可能效率不同。
         * 当input的有效数目不多时，遍历每一个input，向前更新效率更高。因为无效的input值，直接就略过了；
         * 相反，反方向的话，每一个DP状态都需要计算，即使都是空数据。

   * 在Top-Down模式中，貌似天然考虑数据向后依赖。
   * 能用DP做的，是因为它有最优子结构（optimal sub-structures）。所以，只有按照依赖关系更新DP表，才能够减少计算。
      * 确定子结构会被多次用到；DP保证它只计算一次。
      * 以DP表为出发点考虑，DP表中的值，意义是什么？怎样才能减少更新次数/依赖项。（考虑 0-1背包 和 完全背包)
   * 和 DAG 互相转换来帮助思考。

# Solution Space

一个程序（一个具体的题）能给出正确的输出，就完成了任务。虽然大多数时候，我们无法像计算1+1=2那样直接得出最终结果，但我们知道这个目标输出是在一个范围之内/符合一定模式。

这个范围/模式/空间可以从各种角度去考虑。
* 从包含最终解的所有排列组合；
* 从输入参数的范围得到输出的所有可能。

想出来一个解空间之后，它能够帮助我们：
* 不同的解空间，也对应着不同的思路；
* 如果用brute force，它的复杂度是多少？这样就得知了解决这个问题的复杂度上限；
* 对一个解空间进行分析，想办法把最终目标从这个空间中找出来。

## Complete Search

对解空间中的每一个元素都进行计算/比较/验证，看哪一个/哪些是符合要求的解。
同时在绝大多数情况下，这也是解词问题复杂度的最坏情况。

* 即使是Complete Search，也不是意味着对每一个元素都进行验证筛查。在一步步获得一个解空间的元素过程中，在尽早的步骤中就可以prune掉。（这实际上也是对解空间的分解，有着相同的partial solutions被归为同一类，prune掉了。）

## 空间变换

把解空间变换一下，可能会降低复杂度，或降低维度。
* Convex Hull Optimization. 把原来解空间中的解视为一个点，在一条直线上的所有点就可以作为一条线段来处理。于是把点空间转换为线段空间。对于Convex Hull Optimization来说，在两条线段的交点之前$A>B$，交点之后$A<B$, 这样的话，线段的一半（对应于点空间中的很多点）就能够被整体剔除了。
* 圆和直线间的变换。In geometry, inversive geometry is the study of inversion, a transformation of the Euclidean plane that maps circles or lines to other circles or lines and that preserves the angles between crossing curves. Many difficult problems in geometry become much more tractable when an inversion is applied. <https://en.wikipedia.org/wiki/Inversive_geometry>

## 数据分步处理/预处理

* 升维/降维
   * e.g. 一般graph通过升维转成DAG。
   * e.g. DP降维
* 多pass处理
   * e.g. uva 10738
   * e.g. Kosajaju's algorithm for SCCs finding.
* 原数据先（多次）变形，变形后的结果统一起来得到结果。
   * e.g. uva 11902。先去掉某节点v，然后从0点做DFS，得到的是不依赖v的所有节点。

* 排序/放到合适的数据结构中(实际上就是把数据先处理一遍，保存下来处理后的状态；也可以看作是多pass处理)
* 对于环状的问题，考虑镜像/复制来拓展原数据转换成线性。
* 对于多次查询的问题，一次预处理，利于全部查询。
   * e.g. uva 11643 不考虑边界情况下，(r_a, c_a) <-> (r_b, c_b) 最短距离等于 (r_a + m, c_a + n) <-> (r_b + m, c_b + n)。所以一张 precalculated BFS table 就能适用于所有棋盘位置。
* 对图结构转换成树结构；
   * DAG -> Dominator Tree
* 对树结构建立binary lifting table。

## 证明

### Greedy

除了Complete Search，其它情况下，尤其是Greedy，都需要证明我们的输出确实是最终目标。
* 贪心解 >= 最优解 -> 贪心解 == 最优解；（由于具有optimal-substructure性质，基于更小的子结构对当前结构进行证明。）
* Mathematical Induction. 数学归纳法。$A(0) = C, A(n) > A(n-1)$;
   对于有prune的Complete Serach，和DP，都是一步一步分步骤解决问题的，每一步都是产生了规模更小的子问题。规模大的解依赖于规模小的解。天然就适合用数学归纳法。
* 反证法。最优解的性质有哪些。假设我们的输出不是最优解，想办法得到矛盾。最优解的性质一般比较明确，从它出发进行推导比较容易。
   * 比如要找最大值。先假设 贪心解 < 最大值，然后尝试从最大值经过修改得到贪心值（假设我们总是可以进行这样的修改），但是由于最大值/贪心值的性质，会发现有矛盾/行不通。得到 贪心解 >= 最大值。

例子。
* Coin Change。 {25， 10， 5， 1}。Greedy。先选择25，小于25的时候再选其它的。
   - 只有一枚Coin {1} 的时候，显然成立。
   - 假设对于{10， 5， 1}成立，是成立的。- 且能得出结论：1最多有4个；5最多有1个。
   - 从{10， 5， 1}这个optimal-substructure，我们来考虑{25，10， 5， 1}的情况。
   - 当 sum < 25, 同假设，不必证明。
   - 当 sum >= 25，假设贪心解不是最优解，即最优解中的coin 25少于贪心解的 coin 25数目。
      - 最优解O{10..., 5..., 1...}；贪心解G{25, 10..., 5..., 1...}。
         - {10, 10..., 5..., 1} -> 最优解中的元素可以组合成25，所以O可以被优化成G。 贪心解 > 最优解。
         - {10, 10..., 1...}。1最多只能有4个，所以要想总和大于25，需要{10, 10, 10..., 1...} -> 3个10可以组合成{25, ... 5 ..., 1...}。贪心解 > 最优解。
   - 得证{25，10，5，1}，且得到结论：1最多有4个；5最多有1个，10最多有2个。

* [uva 410] Station Balance。Greedy。最大和最小配对。
   - 首先补全数据，添加一些0元素，是元素数目成为2n。这样拿掉A1和A2n，剩下的就是optimal-substructure。
   - {A1, A2, ... An, ... A2n} 。我们证明(A1, A2n)的贪心解 <= 最优解。
   - 令最优解的组合是O{(A1, Aj), (A2n, Ai)}，用它和贪心解G{(A1, A2n), (Ai, Aj)}比较。
   - 令M是平均值，|A1+Ai-M|+|A2n+Aj-M| 比较 |A1+A2n-M|+|Ai+Aj-M|。
      - 把G中的A1和Ai交换，就得到了O。由于Ai>A1，我们令Ai=A1+delta_i，即O对应的sum写为 |A1 + delta_i + A2n - M| + |Ai - delta_i + Aj - M|。
      - 由于A2n - M大于0，所以第一个绝对值OA的值比原来（即G）多出来delta_i。
      - 由于总和是一样的，对应的，第二个绝对值OB里边比原来多减一个delta_i。因为|X-delta_i| >= |X| - |delta_i|，所以OB最终最多比原来（即G）能减少delta_i。
      - 所以 OA+OB - G >= 0。由于O是最优解，所以O=G。

* [uva 10382] Interval Covering Problem。Greedy。按照左边坐标排序。然后在保证左边没有空的情况下，选择右边覆盖到最远的interval。
   - 首先，必须左边没有空隙；否则留着的空隙将来还是要做和现在相同的处理。既然先做后都可以，我们选择先做。
   - 假设有最优解，我们用Greedy的选择去替换最优解，可以知道不会有更坏的结果。

* [uva 481] LIS (Longest Increasing Sequence)。DP & Greedy。
   - Greedy.
      - DP[i] 保存的是，到目前位置j，长度为i的所有subsequence中，末尾值最小的那一个。
      - 假设有其它最优解。用我们DP[i]对应的子序列去替换最优解，可知不会有更坏的结果。
   - Bottom-Up DP. 假设到目前位置j，DP所有元素都已被证明。
      - j+1的加入，会影响到DP的那个值，就update哪个值。（DP是递增的，实际上只影响到一个值）

* [uva 108] Max Sum。DP & Greedy。
   - 考虑一维情况 [uva 507]。DP[i]保存的是末尾是i的时候Max Sum。
   - Bottom-UP DP. 假设DP[i]已经证明：
      - 当 DP[i] + A[i+1] 大于0，它就是DP[i+1]。
      - 当 DP[i] + A[i+1] 小于0，最好情况只能是什么都不选DP[i+1] = 0。

* MST and its variants
   - Greedy.
   - 假设存在最优解，不包含当前greedy的这条边。通过用这条边替换最优解的某条边，得到了更优解。

### Game Theory

例子。
* UVA 847.
   - A先手，具有优势。
   - 第一步，A可以选择2-9。
      - 所以，targe在[2, 9]范围内，A获胜。(A1选9)
   - 第二步，在第一步的基础上，B被动得到的范围是[2, 9]。这个范围内，B最低可以拿到2*9=18。
      - 所以，target在[10, 18]范围内，B获胜。
   - 第三步，A具有第一步的先手优势，不同的选择导致第二步B给出的范围也不同。
      - A1=2，B2=[4, 18], 当18 < target <= 36时A可获胜。(A3选9)
      - A1=3, B2=[6, 27], 当27 < target <= 54时可获胜。(A3选9)
      - ...
      - A1=9, B2=[18, 81], 当81 < target <= 18*9时A可获胜。（A3选9）
      - (速记) A能保证最低拿到 9 * 2 = 18；然后A选9，所以最低能拿到 9 * 2 * 9。

      - 所以，target在[18, 18*9]范围内，A获胜。

   - 第四步，A具有先手优势，B只能被动得到一个范围。
      - B能保证在这一步得到的值 >= 2 * 9 * 2 = 18*2（每一步A都选最小的2，B自己选最大的9）
      -                       <= 9 * 2 * 9 = 18*9
      - B被动得到的范围是[18 * 2, 18 * 9]。这个范围内，B最低可以拿到18 * 2 * 9。
      - 所以，target在[18*9 + 1, 18 * 9 * 2]范围内，B获胜。


# 分解 Solution Space

哪些元素可以放到一起考虑？把有相同特性/变量的元素放到一起，它们所具有的相同变量就不用重复计算了。这样问题的复杂度就变成了有多少个变量以及每个变量的复杂度是多少了。

正如数学上对于一个空间/目标有无数种分解形式一样，具体的解空间也有无数种分解法。如何分解它利于找到最终解，实际上需要对目标解空间有一定的了解才能做到。
* 从简单的形式出发，在草稿纸上画一画，看得到的解在解空间中有什么性质。N=1，N=2；
* 多个限定的情况下，先限定一定的条件，在简单情况下分析问题；也就是说，尝试分解限定条件。
* 比较空间中的两个元素。比如最优解和贪心解的比较。分析两个元素之间如何转化，得到最优解或最优解的性质。
* 从两个方向思考：由子空间如何扩展成大空间；大空间如何分解成小空间；
* 思考的过程和程序的实现经常是相反顺序的；
   * 比如动态规划，思考的方向是大空间如何从小空间得到；程序实现的时候，先从小空间开始逐步扩大。
   * 比如思考的时候可能是，先按照组合对解空间分层，然后再每个层内考虑不同排列；程序实现的时候，可能就是先按照最优排列整个排个序，然后在其基础上考虑不同组合。

## 从解空间的角度去分析和思考

* Quick Sort.
   * 过一遍输入数据，分为A，B集合，让A中的元素都小于B中的元素。
   * 子空间的每个元素都满足：A集合元素在B集合元素之前。
   * 分别对A，和B集合中的元素排序。（问题规模变小了）

* Merge Sort.
   * 从输入数据考虑，分为A，B集合。
   * 对A排序，相当于原来解空间中，找到一个子空间。这个子空间的每个元素，A的数据是排好序的。B同理。（问题规模变小了）
   * A对应的子空间，和B对应的子空间，它们的交集中，有一个是最终解。通过合并步骤把它找出来。


## 分解解空间 - 提取子结构

分解后得到空间子集，一般应该与原空间有相同的结构，但问题规模变小了。有点像因式分解。

* 从空间整体上对它进行分解。对空间分层；树结构；
   * 比如对于空间中的解是一个序列的情况，把包含相同元素但不同排列的解都放到同一层；然后在每一个层中，再考虑元素的排列。
* 解空间可以由子问题/子结构的解空间组成。动态规划；贪心；
* 分解之后的子空间，尽量避免互相交叠，尽量避免重复计算。动态规划；
* 最优化思路。在解空间中，从一个普通解出发，不断优化得到最优解。很显然，类似于梯度下降，不是所有空间都能得到全局最优解。
* 找到正确的切割方式切割空间，优化掉某些值。一定有某些值是优于其它值的，找到它们就相当于正确分解了解空间。找到朝向最优解的切入点。比如，极端情况下，时域转成频域处理。

## 合并子空间

解空间会分解成多个子空间，每个子空间都有自己的解。需要合并子空间的解，得到原始解空间的解。
理论上：
* 每个元素都是一个子空间，复杂度 = 合并复杂度 = Complete Serach复杂度。
* 解空间就是自己的子空间，复杂度 = Complete Serach复杂度。
* 介于以上极端情况中间的，比如DP，复杂度 = 全部子空间数目 * 合并复杂度。（全部子空间数目指的是递归展开后的全部子空间，比如DP的状态表的每一个元素就是一个子空间。）

## 从图的角度观察解空间

解空间的构造：提取参数成为节点；节点之间的转移。
比如SPOJ 101，并不是题目中的图节点就是解空间的图节点，题目中的边就是解空间节点间的边。
* 直接在原图上做搜索的话，是一个搜索问题。但由于带了一个时间参数，多次走到同一个节点的时候，这个节点也不能算作重复计算，导致无法用下面的方法优化，导致搜索的解空间太大。
* 根据参数构造节点，（原节点，时间）一起作为解空间中的节点。这样的好处是，一个节点访问一次就可以，不必要重复计算（只需要计算这个节点的最优值）。同时也可以看到，由于时间值是单调的，解空间的这个图是一个DAG。不再是一个搜索问题，而是成为一个DP问题。

### A node can be reached via any one of its neighbors. 搜索问题，只要有一条路径能到达就行。

|图类型|DFS|BFS/A*|IDS/IDA*|
|-----|---|------|---------|
|Trees with huge amounts of V/E|通过pruning减少运算|内存问题|时间空间的折衷：好的估计函数保证朝target方向DFS展开，increasing depth策略解决内存问题|
|Graphs with reasonable vertices but too many edges|通过bitmask运算，避免重复vertices访问（标记已访问的vertices），和不必要的edges遍历（一个vertex的edges用bit array表示，LSB：从后往前取值为1的bits）|天然适合SSSP问题，但有内存问题|时间空间的折衷：好的估计函数保证朝target方向DFS展开，increasing depth策略解决内存问题|
|Graphs with too many vertices and edges|X|天然适合SSSP问题，但有内存问题|时间空间的折衷：好的估计函数保证朝target方向DFS展开，increasing depth策略解决内存问题|


### A node relies on all of its neighbors. 比如需要从所有邻接点中找出值最小的那一个（依赖关系说明是DAG）。

|图类型|DFS|BFS|example|
|-----|---|------|----|
|DAG: V和E数量都很少|Top-down DP|Bottom-up DP|many|
|DAG: V的数量很大，但是对最终target来说，依赖的有限|Top-down DP + Balanced BST Memo Table|X|0-1 Knapsack with a large state space|

### 如何构建状态/状态转移。

|输入|构建图|example|
|-----|----|----|
|输入图的节点个数$<2^{20}$|输入图节点的组合用bitmask表示，这个bitmask作为新的节点/状态；状态转移由输入图决定。一般生成一个DAG，使用DP计算。|DP-TSP; Minimum Weight Perfect Matching|
|输入值范围内每一个值作为节点|一般是一个DAG，使用DP计算。|0-1 Knapsack; Subset Sum; Coin Change variants|


## 从树结构到线性结构的变换

### 用线性结构表示的树

实际上就是Tree，通过index的关系，形成树结构
* Binary Heap
* Fenwick Tree
* Segment Tree

### 将树通过traversal线性化

会丢失掉原来Tree的一些信息。但实际应用中，这些信息可能是无用，或者可算出来的。
* LCA问题。在线性结构中使用RMQ。
* Suffix Tree -> Suffix Array
   * 线性结构排序。使用suffix之间的重复/关联性，以及counting sort，O(nlogn)就能对所有suffix排序。
   * string matching。在线性排序结构中，二分法找。O(mlogn)
   * Longest Common Prefix / Longest Repeated Substring / Longest Common Substring。使用suffix之间的重复/关联性，能够在O(n)计算出来所有suffix的LCP。



# Complexity

$O(n)$                        1M - 1G\
$O(n\log{n})$                 200K - 100M\

$O(n^2)$                      1K - 30K\
$O(n^3)$                      100 - 1K\
$O(n^4)$                      30 - 200\
$O(n^5)$                      20 - 70\

$a(n) = a(n-1) + a(n/2)$      200 - 800\

$fibonacci                    30 - 40\
$O(2^n)$                      20 - 30\
$O(10^n)$                     6 - 9\

$O(n!)$                       10 - 13\
$O(n^n)$                      8 - 10
