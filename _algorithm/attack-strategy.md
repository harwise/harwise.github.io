---
layout: default
title: Problem Solving Strategies
---

{% include katex.html %}

# Ad-hoc

* 从input开始考虑（遍历每一个input），前进一步步到达output；或者从output开始考虑（遍历每一个output），后退一步步到达input。
   * 根据input，output的形式，选择合适方法。
      * UVa 10205。直接从output反推回去，直接得到答案，实现上更高效。
      * UVa 10189。从input开始，更新output。因为只有input有值得时候才需要处理，所以更高效。

* 从上一步得到当前步的时候，（或反向，或从当前步到下一步）
   * 分析当前状态；
   * 分析上一步的状态；
   * 从上一步到当前步有哪些变化；上一步的信息/结果是不是有助于当前步的分析/计算。

* DP.
   * 实际上就是先做complete search，然后提取出overlapping sub-structures。
      - 如果只考虑第一步的话，可能会忽略一些重要参数。需要多考虑几步；或者进一步从一个中间状态开始分析。
   * 在Bottom-Up模式中，可以双向考虑，数据向前更新(前进一步能到达哪些位置)，以及数据向后依赖（要依赖之前哪些数据能得到当前位置的值）。两个方向虽然本质是一样的，但某个方向更有助于理清楚逻辑。
   * 在Top-Down模式中，貌似天然考虑数据向后依赖。
   * 能用DP做的，是因为它有最优子结构（optimal sub-structures）。所以，只有按照依赖关系更新DP表，才能够减少计算。
      * 确定子结构会被多次用到；DP保证它只计算一次。
      * 以DP表为出发点考虑，DP表中的值，意义是什么？怎样才能减少更新次数/依赖项。（考虑 0-1背包 和 完全背包)
   * 和 DAG 互相转换来帮助思考。

# Solution Space

一个程序（一个具体的题）能给出正确的输出，就完成了任务。虽然大多数时候，我们无法像计算1+1=2那样直接得出最终结果，但我们知道这个目标输出是在一个范围之内/符合一定模式。

这个范围/模式/空间可以从各种角度去考虑。
* 从包含最终解的所有排列组合；
* 从输入参数的范围得到输出的所有可能。

想出来一个解空间之后，它能够帮助我们：
* 不同的解空间，也对应着不同的思路；
* 如果用brute force，它的复杂度是多少？这样就得知了解决这个问题的复杂度上限；
* 对一个解空间进行分析，想办法把最终目标从这个空间中找出来。

## Complete Search

对解空间中的每一个元素都进行计算/比较/验证，看哪一个/哪些是符合要求的解。
同时在绝大多数情况下，这也是解词问题复杂度的最坏情况。

* 即使是Complete Search，也不是意味着对每一个元素都进行验证筛查。在一步步获得一个解空间的元素过程中，在尽早的步骤中就可以prune掉。（这实际上也是对解空间的分解，有着相同的partial solutions被归为同一类，prune掉了。）

## 空间变换

把解空间变换一下，可能会降低复杂度，或降低维度。
* Convex Hull Optimization. 把原来解空间中的解视为一个点，在一条直线上的所有点就可以作为一条线段来处理。于是把点空间转换为线段空间。对于Convex Hull Optimization来说，在两条线段的交点之前$A>B$，交点之后$A<B$, 这样的话，线段的一半（对应于点空间中的很多点）就能够被整体剔除了。
* 圆和直线间的变换。In geometry, inversive geometry is the study of inversion, a transformation of the Euclidean plane that maps circles or lines to other circles or lines and that preserves the angles between crossing curves. Many difficult problems in geometry become much more tractable when an inversion is applied. <https://en.wikipedia.org/wiki/Inversive_geometry>

## 数据分步处理/预处理

* 多pass处理
   * e.g. uva 10738
* 排序/放到合适的数据结构中(实际上就是把数据先处理一遍，保存下来处理后的状态；也可以看作是多pass处理)
* 对于环状的问题，考虑镜像/复制来拓展原数据转换成线性。
* 对于多次查询的问题，一次预处理，利于全部查询。
* 对图结构转换成树结构；
   * DAG -> Dominator Tree
* 对树结构建立binary lifting table。

## 证明

### Greedy

除了Complete Search，其它情况下，尤其是Greedy，都需要证明我们的输出确实是最终目标。
* 贪心解 >= 最优解 -> 贪心解 == 最优解；（对部分解进行证明。因为贪心本身就认为产生的部分解就是最优的。）
* Mathematical Induction. 数学归纳法。$A(0) = C, A(n) > A(n-1)$;
   对于有prune的Complete Serach，和DP，都是一步一步分步骤解决问题的，每一步都是产生了规模更小的子问题。规模大的解依赖于规模小的解。天然就适合用数学归纳法。
* 反证法。最优解的性质有哪些。假设我们的输出不是最优解，想办法得到矛盾。最优解的性质一般比较明确，从它出发进行推导比较容易。
   * 比如要找最大值。先假设 贪心解 < 最大值，然后尝试从最大值经过修改得到贪心值（假设我们总是可以进行这样的修改），但是由于最大值/贪心值的性质，会发现有矛盾/行不通。得到 贪心解 >= 最大值。

例子。
* Coin Change。 {25， 10， 5， 1}。Greedy。先选择25，小于25的时候再选其它的。
   - 只有一枚Coin {1} 的时候，显然成立。
   - 假设对于{10， 5， 1}成立，是成立的。
   - 考虑{25，10， 5， 1}的情况。
   - 当 sum < 25, 同假设，不必证明。
   - 当 sum >= 25，假设贪心解不是最优解，即最优解中的coin 25少于贪心解的 coin 25数目。
      - 最优解O{10..., 5..., 1...}；贪心解G{25, 10..., 5..., 1...}。
         - {10, 10..., 5..., 1} -> 最优解中的元素可以组合成25，所以O可以被优化成G。 贪心解 > 最优解。
         - {10, 10..., 1...}。1最多只能有4个，所以要想总和大于25，需要{10, 10, 10..., 1...} -> 3个10可以组合成{25, ... 5 ..., 1...}。贪心解 > 最优解。

* [uva 410] Station Balance。Greedy。最大和最小配对。
   - {A1, A2, ... An, ... A2n} 。我们证明(A1, A2n)的贪心解 <= 最优解。
   - 令最优解的组合是O{(A1, Aj), (A2n, Ai)}，用它和贪心解G{(A1, A2n), (Ai, Aj)}比较。
   - 令M是平均值，|A1+Ai-M|+|A2n+Aj-M| 比较 |A1+A2n-M|+|Ai+Aj-M|。
      - 把G中的A1和Ai交换，就得到了O。由于Ai>A1，我们令Ai=A1+delta_i，即O对应的sum写为 |A1 + delta_i + A2n - M| + |Ai - delta_i + Aj - M|。
      - 由于A2n - M大于0，所以第一个绝对值OA的值比原来（即G）多出来delta_i。
      - 由于总和是一样的，对应的，第二个绝对值OB里边比原来多减一个delta_i。因为|X-delta_i| >= |X| - |delta_i|，所以OB最终最多比原来（即G）能减少delta_i。
      - 所以 OA+OB - G >= 0。由于O是最优解，所以O=G。

* [uva 10382] Interval Covering Problem。Greedy。按照左边坐标排序。然后在保证左边没有空的情况下，选择右边覆盖到最远的interval。
   - 首先，必须左边没有空隙；否则留着的空隙将来还是要做和现在相同的处理。既然先做后都可以，我们选择先做。
   - 假设有最优解，我们用Greedy的选择去替换最优解，可以知道不会有更坏的结果。

* [uva 481] LIS。DP & Greedy。
   - Greedy.
      - DP[i] 保存的是，到目前位置j，长度为i的所有subsequence中，末尾值最小的那一个。
      - 假设有其它最优解。用我们DP[i]对应的子序列去替换最优解，可知不会有更坏的结果。
   - Bottom-Up DP. 假设到目前位置j，DP所有元素都已被证明。
      - j+1的加入，会影响到DP的那个值，就update哪个值。（DP是递增的，实际上只影响到一个值）

* [uva 108] Max Sum。DP & Greedy。
   - 考虑一维情况 [uva 507]。DP[i]保存的是末尾是i的时候Max Sum。
   - Bottom-UP DP. 假设DP[i]已经证明：
      - 当 DP[i] + A[i+1] 大于0，它就是DP[i+1]。
      - 当 DP[i] + A[i+1] 小于0，最好情况只能是什么都不选DP[i+1] = 0。

* MST and its variants
   - Greedy.
   - 假设存在最优解，不包含当前greedy的这条边。通过用这条边替换最优解的某条边，得到了更优解。

### Game Theory

例子。
* UVA 847.
   - A先手，具有优势。
   - 第一步，A可以选择2-9。
      - 所以，targe在[2, 9]范围内，A获胜。(A1选9)
   - 第二步，在第一步的基础上，B被动得到的范围是[2, 9]。这个范围内，B最低可以拿到2*9=18。
      - 所以，target在[10, 18]范围内，B获胜。
   - 第三步，A具有第一步的先手优势，不同的选择导致第二步B给出的范围也不同。
      - A1=2，B2=[4, 18], 当18 < target <= 36时A可获胜。(A3选9)
      - A1=3, B2=[6, 27], 当27 < target <= 54时可获胜。(A3选9)
      - ...
      - A1=9, B2=[18, 81], 当81 < target <= 18*9时A可获胜。（A3选9）
      - (速记) A能保证最低拿到 9 * 2 = 18；然后A选9，所以最低能拿到 9 * 2 * 9。

      - 所以，target在[18, 18*9]范围内，A获胜。

   - 第四步，A具有先手优势，B只能被动得到一个范围。
      - B能保证在这一步得到的值 >= 2 * 9 * 2 = 18*2（每一步A都选最小的2，B自己选最大的9）
      -                       <= 9 * 2 * 9 = 18*9
      - B被动得到的范围是[18 * 2, 18 * 9]。这个范围内，B最低可以拿到18 * 2 * 9。
      - 所以，target在[18*9 + 1, 18 * 9 * 2]范围内，B获胜。


# 分解 Solution Space

哪些元素可以放到一起考虑？把有相同特性/变量的元素放到一起，它们所具有的相同变量就不用重复计算了。这样问题的复杂度就变成了有多少个变量以及每个变量的复杂度是多少了。

正如数学上对于一个空间/目标有无数种分解形式一样，具体的解空间也有无数种分解法。如何分解它利于找到最终解，实际上需要对目标解空间有一定的了解才能做到。
* 从简单的形式出发，在草稿纸上画一画，看得到的解在解空间中有什么性质。N=1，N=2；
* 多个限定的情况下，先限定一定的条件，在简单情况下分析问题；也就是说，尝试分解限定条件。
* 比较空间中的两个元素。比如最优解和贪心解的比较。分析两个元素之间如何转化，得到最优解或最优解的性质。
* 从两个方向思考：由子空间如何扩展成大空间；大空间如何分解成小空间；
* 思考的过程和程序的实现经常是相反顺序的；
   * 比如动态规划，思考的方向是大空间如何从小空间得到；程序实现的时候，先从小空间开始逐步扩大。
   * 比如思考的时候可能是，先按照组合对解空间分层，然后再每个层内考虑不同排列；程序实现的时候，可能就是先按照最优排列整个排个序，然后在其基础上考虑不同组合。

## 从解空间的角度去分析和思考

* Quick Sort.
   * 过一遍输入数据，分为A，B集合，让A中的元素都小于B中的元素。
   * 子空间的每个元素都满足：A集合元素在B集合元素之前。
   * 分别对A，和B集合中的元素排序。（问题规模变小了）

* Merge Sort.
   * 从输入数据考虑，分为A，B集合。
   * 对A排序，相当于原来解空间中，找到一个子空间。这个子空间的每个元素，A的数据是排好序的。B同理。（问题规模变小了）
   * A对应的子空间，和B对应的子空间，它们的交集中，有一个是最终解。通过合并步骤把它找出来。


## 分解解空间 - 提取子结构

分解后得到空间子集，一般应该与原空间有相同的结构，但问题规模变小了。有点像因式分解。

* 从空间整体上对它进行分解。对空间分层；树结构；
   * 比如对于空间中的解是一个序列的情况，把包含相同元素但不同排列的解都放到同一层；然后在每一个层中，再考虑元素的排列。
* 解空间可以由子问题/子结构的解空间组成。动态规划；贪心；
* 分解之后的子空间，尽量避免互相交叠，尽量避免重复计算。动态规划；
* 最优化思路。在解空间中，从一个普通解出发，不断优化得到最优解。很显然，类似于梯度下降，不是所有空间都能得到全局最优解。
* 找到正确的切割方式切割空间，优化掉某些值。一定有某些值是优于其它值的，找到它们就相当于正确分解了解空间。找到朝向最优解的切入点。比如，极端情况下，时域转成频域处理。

## 合并子空间

解空间会分解成多个子空间，每个子空间都有自己的解。需要合并子空间的解，得到原始解空间的解。
理论上：
* 每个元素都是一个子空间，复杂度 = 合并复杂度 = Complete Serach复杂度。
* 解空间就是自己的子空间，复杂度 = Complete Serach复杂度。
* 介于以上极端情况中间的，比如DP，复杂度 = 全部子空间数目 * 合并复杂度。（全部子空间数目指的是递归展开后的全部子空间，比如DP的状态表的每一个元素就是一个子空间。）

# Complexity

$O(n)$         1M - 1G\
$O(n\log{n})$  200K - 100M\
$O(n^2)$       1K - 30K\
$O(n^3)$       100 - 1K\
$O(n^4)$       30 - 200\
$O(n^5)$       20 - 70\
$O(n!)$        10 - 13\



